- dynamic instruction scheduling
	- instruction들은 pipeline에 들어온 순서가 아닌 operands가 준비되면 병렬적으로 실행된다.
	- when completion, outcome of insts are sorted in order so that they can be used to make process state in origin order when interrupt occrus.
- SuperScalar
	- using ILP, SS executes instructions in parallel individually
	- IPC is 1 in pipelining, but IPC can be greater than 1 using SS
- binary compatibility
	- we can still execute any machine program for previous CPU model on recent model
- Sequential execution model
	- fetch and execution instruction sequentially at a time by increasing PC once an inst is completed
	- precise state
		- once an interrupt occurs, PVS must be conserved as the state at that moment and interrupted inst should be stopped
		- then we can restart from the conserved PVS simply
	- but SS violates Sequential execution model
		- So binary must be considered as what to do not how to do
		- then SS take sequentiality from a binary only if it is necessary, if not remove it to achieve ILP.
		- but processor is still seemed to use sequential execution model in terms of outside view
- Elements of High performance processing
	- SS focusses on parallel execution of instructions not latency but be careful not to increase the latency due to increment of HW complexity by parallel execution
	- Determination of dependencies btw insts to do parallel inst processing
	- Enough HW resources
	- Data forwarding techniques
	- Method for communicating for data memory values btw load and store inst
	- Method for commiting PVS in order
- Program Representation, Dependences and Parallel Execution
	- inst is control dependent on its preceeding inst because of sequential semantic of Architecture
	- To increase ILP, overcome the control dependency
- Instruction Fetching and Branch Prediction
	- Instruction Cache
		- save recently used inst to reduce latency and bandwidth of IF
		- As examining PC is in Inst Cache, if there is then cache hit, if not cache miss
		- Superscalar can do multiple inst execution if IF fetch multiple insts from cache memory per cycle
		- For this separating data cache and inst cache is needed to support high bandwidth of inst fetch
	- Instr. buffer
		- instr. buffer is for the case of cache miss. We accumulate insts in instr. buffer and use insts in buffer when inst cache miss occurs so that inst fetch process is delayed
	- conditional branch inst is important to improve Superscalar due to delay from branch resolution
		- Recognization conditional branch
			- Include decoding information of inst in inst cache, so that we can verify inst type fast
			- Do this in pre-decoding process with extra information with inst in cache
		- Determining the branch outcome
			- branch resolution can be delayed so that there exists control dependency
			- Instead of waiting for resolution, we predict outcome of branch
				- using static information of binary data from compiler
				- using dynamic information in run time from branching history
		- Computing branch targets
			- using branch target buffer recording last branch target
		- Transferring control
			- there exists delay for processing branch inst
			- To mask delay, using delay slot or instruction acculated in instr. buffer
- Instruction Decoding, Renaming and Dispatch
	- decode phase
		- set up execution tuples for each inst
			- tuple includes operation, location of operands and dest. of result of operation
		- renaming logical register to physical address to avoid WAR and WAW dependency
			- Option1 : using greater physical RF than logical RF
				- mapping logical register to physical register with mapping table
				- track the free phsical register with free list
					- Method1 : add counter to each physical register
						- once renaming, increment counter
						- once used by an inst in reality, decrement counter
						- then whenever counter value is 0, the physical register is free
					- Method3 : waiting to physical register is written back and committed(i.e. retiring from pipeline)
			- Option2 : using physical RF which has same size with logical RF
				- ROB is needed to sustain insts in order and hold insts not committed yet
				- implement ROB circular buffer HW with head & tail pointers
					- once an inst is dispatched then it is assigned to entry at tail of ROB
					- If inst is complete and also reach to head of ROB, then commit the result to PVS meaning that it is safe from misprediction and interrupt
					- We can know that the physical registers from the tail of ROB are free
			- source register designators are used to find their current physical register in mapping table
			- Instruction Dispatch stalls when free list is filled 100%
- Instruction Issuing and Parallel Execution
	- Single Queue Method
		- If there is no out of order issue, then renaming is unnecessary
		- using reservation bit, manage the availability of source register
			- If an inst is issued who writes back the register, then the register is reserved
			- When that inst completes, the register become available
		- An inst can be issed if its source registers are all available
	- Multiple Queue Method
		- In each queue, an inst is issued in order, but an inst is issued out of order with repect to other queues
		- The case of using renaming only for the register loaded from memory
			- then a load inst can be issued out of order preceeding other insts so that it can fetch the memory data in advance
	- Reservation Stations
		- all of reservation stations monitor their source register whether available or not
		- once an inst is dispatched, bring an available operands value to reservation station from RF
		- compare the operand designators of unavailable register with disignators of completed insts everytime insts complete
		- If matches, then the outcomes of completed insts are taken to matched reservation stations
		- If all operands are available, the inst can be issued
		- when issed, the inst takes the destination designator to compare with operands of reservation station when completes
		- Advaned reservation station not take the value but use pointer directing the location where the value exists (RF or ROB)
- Handling Memory Operations
	- To reduce latency, use data cache
	- On Load and Store inst, cannot know memory address where to access until execution of calculating address
	- load/store inst are issed to execution phase to calculate the address
	- after get address, address translation is needed to know physical address and using TLB is used to do this faster
	- address translation and memory access is not done serially but parallely, then the translated address is used to compare with cache tag so that determining cache hit
	- allowing execution memory operations overlapped and out of order is not practical due to memory size greater than RF
		- not using rename tables with information of each memory location, but take information only for the memory locations of pending memory operations
		- then just search this when memory access is required
	- To execute multiple memory operations simultaneously to avoid bottleneck, memory hierarchy must be multiported
		- Because not many memory operations proceed to upper levels in memory hierarchy, multiported primary cache is enough
		- Multiporting is implemented with muliple banks of memory or multi requests of memory operation in series per cycle
		- For overlapping of memory operations, when cache miss occurs other operations still proccess ; i.e. the memory hierarchy is non-blocking
	- To keep the sequential semantic even with overlapping memory operations, Store Address Buffer is introduced
		- include all of pending store insts
		- before load & store Store Buffer check whether there exist pending operation with same address
	- MHSR : mis handling status register
		- when cache miss, bring the line including access location to cache and record pending status using MHSR
		- So that other process still keep going and it allows multiple memory operations to be overlapped
- Committing State
	- To keep the sequetial sementic, even with out of order execution virtually
	- Recovery of precise state methods must manage the state updated by operation and required for recovery
	- Option1 : Save the state of machine at a certain time ; History buffer or checkpoint
		- The state is updated as operation execution completes
		- when precise state is required, recovery from history buffer
		- when an inst is committed so that retire from speculative state, remove that from history buffer
	- Option2 : Sparate the state of machine into physical state and logical state
		- update physical state as operation completes but save in ROB if it is still in speculative state
		- when an inst escapes from speculative state, retire the inst from ROB to architecture register file
			- if store operation is committed, wirte the data from store buffer to memory and retire from store buffer
		- In ROB, there are places for outcome of execution not committed 
		- Also there are places for PC of the inst and an interrupt condition that can occur as the inst executes to inform the commit logic when interrupt should be initiated and PC for precise interrupt state
		- ROB is useful to the renaming method that physical registers have all of the renamed values
			- So that ROB don't have to save the values not committed yet, but values are written to physical RF
			- But ROB holds the control and interrupt information to return physical registers to free list when the inst who write back overlapped register is committed
			- also those information can be used to recover the precise state of mapping table when interrupt occurs
- The Role of SW
	- scheduling instructions statically
	- increase likelihood that instructions are issued simultaneously
		- arrange instructions to satisfy the conditions to execute insts parallely on Superscalar
		- when arrange insts, it must be considered that dependency btw insts and resources to be used in uArchitecture so that all of insts executed parallely can be executed independently with repect to each others
	- decrease likelihood that an instruction wait for outcome of previous instruction
		- an inst which produces a value to be used by other insts is placed in advance of consumer insts in binary code
- MIPS R10k
	- fetching 4 insts from inst cache where insts are pre-decoded at once time
	- verify inst type by creating extra 4 bits in pre-decoding phase just after fetching
	- branch insts are predicted using prediction table in inst cache which has 512 entries with 2bit value encoding branch history
	- If predict to branch taken, it takes a cycle to redirect inst fetching. During redirecting, sequential insts are fetched in a "resume cache" to be ready for misprediction
		- resume cache has space for four blocks of insts so that it can handle four branch prediction
	- After inst fetching, insts are decoded and registers of operands are renamed and dispatched to appropriate instruction queue one of three queues ; memory, integer, floating point
		- each queue has 16 entries and blocks dispatch when fulls
		- Once an inst is dispatched, the reservation bit of physical register for result register is set busy
		- Each queue is a reservation station which holds the physical register designators pointing the data not value
		- Each inst in the queue examine the "global register reservation bits" for availability of its operands. Then the inst can be issued according to availability of its functional unit if the global reservation bits are not busy
		- But memory queue issues the insts in order, which make address hazard detection simpler
	- Five functional units ; an address adder, two integer ALUs, a floating point muliplier/divider/sqr and a floating point adder
	- primary cache on-chip and secondary cache off-chip
		- primary cache blocks only when secondary cache miss occurs
	- manage precise state using ROB
		- commit the insts in order up to 4 at a time
			- the new copy of physical register become new architectural precise state
		- when an inst is committed, the old physical register of logical register which is written back is free return
		- ROB holds exception condition for not committed insts and interrupt occurs when the inst with exception reach to head of queue i.e. ready to commit
		- restore the mapping table as if younger insts not exist using the information of insts following the interrupting inst
	- When branch prediction, processor capture the register mapping tabla at that moment
		- then mapping table can be restored rapidly when misprediction
		- Also resume cache where the insts following the branch inst sequentially exist is used to process inst without latency
- Alpha 21164
	- fetch 4 insts from inst cache at a time
	- two inst buffer, each buffer can hold insts up to 4
	- insts are issued from buffer in order and buffer must be empty to use next buffer
		- when operands are all ready, the inst is issued to functional unit
		- like single queue
	- only one branch prediction
		- branch history entry for each inst exists in inst cache
		- each entry has two bit encoding branch history
		- when another branch inst is encountered, stall an issue untill previous branch inst is resolved
	- two level memmory hierarchy on-chip
		- primary caches are separted for data and inst
			- allow to access to primary cache on one cycle with fast clock frequency
			- sustain for a number of cache miss using six entries of "miss address file" (MAF) containing the address and target register to load that misses
			- when the address is overlapped by other entry of MAF, they are merged to same entry of MAF so that cover more than six cache miss
		- sencondary is shared for data and inst
	- With in order issue, pipeline is just like ROB so that pipeline can bypass to RF to commit
		- but floating point insts are allowed to update RF out of order, So floating point inst exception not always keep a precise architectural state
		- 
- AMD K5
	- complex instruction set not designed for pipeline
	- use variable length instructions meaning that an inst must be decoded to find start point of next inst. So that an inst is pre-decoded when fetched to inst cache
	- five pre-decode bits per inst byte including information that the byte is whether begin or end and opcode or operand
	- insts are fetched from inst cache to byte queue and waiting for dispatch
	- branch prediction within inst cache
		- one prediction entry per line of cache has a single bit to verify preceeding branch inst is taken or not and pointer informing where to find target inst in inst cache so that reduces the latency
	- consume two cycle to decode inst due to complex inst set
		- read inst bytes from the byte queue and convert to RISC format called ROP up to 4 ROPs by using HW during one cycle ; can use lookup table(ROM)
		- inst can read operand data from the first cycle and are dispathced to reservation stations upt to 4 ROPs per cycle
		- inst wait for available operand in reservation station and when available, it is issued to appropriate functional unit
			- when ROPs are issued, they are dispatched to ROB
			- reservation station is separated for each functional unit
		- data cache with 4 banks
			- overlapped load/store operation with different banks
		- 16 entry ROB guarantees a precise state for exception and branch misprediction
			- each entry holds result data by bypassing from functional unit which completes execution until commit



